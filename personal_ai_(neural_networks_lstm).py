# -*- coding: utf-8 -*-
"""Personal: AI (CNN: LSTM).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12GvxqKikfpcjRqqjqADY581B4lyQ1Xma
"""

# LSTM Network

# Imports
import numpy as np
import sys
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.utils import to_categorical

# Data Manipulation
textFile = open("//content//drive//MyDrive//Coding//Personal Projects//1: Artificial Intelligence//Resources//GreatExpectations.txt").read().lower()
chars = sorted(list(set(textFile)))
char_to_int = dict((c, i) for i, c in enumerate(chars))

# Input : Output
seq_length = 100
dataX = []
dataY = []
for i in range(0, len(textFile) - seq_length, 1):
	seq_in = textFile[i:i + seq_length]
	seq_out = textFile[i + seq_length]
	dataX.append([char_to_int[char] for char in seq_in])
	dataY.append(char_to_int[seq_out])
n_patterns = len(dataX)
print("Total Patterns: ", n_patterns)

# Reshape to [samples, time steps, features], Normalize, One Hot Encode Output Variable
X = np.reshape(dataX, (n_patterns, seq_length, 1))
X = X / float(len(chars))
y = to_categorical(dataY)

# Model LSTM
model = Sequential()
model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(256))
model.add(Dropout(0.2))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')

model.fit(X, y, epochs = 50, batch_size = 128)

# Testing Model
int_to_char = dict((i, c) for i, c in enumerate(chars))
start = np.random.randint(0, len(dataX)-1)
pattern = dataX[start]
print("Random Sampled Text:")
print("\"", ''.join([int_to_char[value] for value in pattern]), "\"")
print("Generated Text from Random Sampled Text:")
for i in range(100):
	x = np.reshape(pattern, (1, len(pattern), 1))
	x = x / float(len(chars))
	prediction = model.predict(x, verbose=0)
	index = np.argmax(prediction)
	result = int_to_char[index]
	seq_in = [int_to_char[value] for value in pattern]
	sys.stdout.write(result)
	pattern.append(index)
	pattern = pattern[1:len(pattern)]
